# Neural Network From Scratch

This repository contains a custom neural network implemented from scratch, supporting both regression and classification tasks.

## Components

### 1. Dense Layer

- Fully connected layer.

### 2. ReLU Activation

- Introduces non-linearity to the dense layer.

### 3. Loss Functions

#### a. Mean Squared Error (MSE)

- Used for regression tasks.

#### b. Cross Entropy Loss

- Used for classification tasks.

### Examples
- Example training on different common datasets (EMNIST etc.) are underway.
